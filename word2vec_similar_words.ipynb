{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ed3742-09f5-47f1-a11a-86d6bc407607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mpu\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e175807-8990-4997-baa9-c1786df14249",
   "metadata": {},
   "source": [
    "## 1. Load the vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5725d6c-fff3-42df-9f7c-f518afa747b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_data = mpu.io.read('vocab.pickle')\n",
    "vocab_list = np.array(vocab_data['vocab_list'])\n",
    "inverse_vocab_dict = vocab_data['inverse_vocab_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b51e1a-915e-4896-a75a-a2e5f41e75c0",
   "metadata": {},
   "source": [
    "## 2. Load and normalize the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c45583d-3f1d-4a6e-87a7-e14f1241dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_embedding = np.load('word2vec_embedding.npy')\n",
    "online_embedding = np.load('word2vec_embedding_onlinefull.npy')\n",
    "norm_full_embedding = full_embedding/norm(full_embedding, axis=-1)[:,np.newaxis]\n",
    "norm_online_embedding = online_embedding/norm(online_embedding, axis=-1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385af3d6-6721-4bd6-8177-5d86ac0ee3ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Calculate the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "198daad2-149f-4456-8079-fdc19edfed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sim = norm_full_embedding @ norm_full_embedding.T\n",
    "online_sim = norm_online_embedding @ norm_online_embedding.T\n",
    "\n",
    "np.fill_diagonal(full_sim, 0)\n",
    "np.fill_diagonal(online_sim, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad265889-5c7e-4e5d-bcea-69b6b50ecd82",
   "metadata": {},
   "source": [
    "## 4. Compare the context words found by the full model and the online model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a9468d-81b3-4bb2-bf5e-9a7ecac2eab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************************\n",
      "Full   model target to context: tellus --> sigeia,disguised,thereon,replied,hic,simois,i,sceptres,[UNK],esteem\n",
      "Online model target to context: tellus --> sigeia,disguised,degrees,tongueless,thus,trencher,speeches,remove,greece,ballad\n",
      "**********************************************************************************************\n",
      "Full   model target to context: sigeia --> tellus,hic,simois,disguised,steterat,replied,thereon,[UNK],musty,changes\n",
      "Online model target to context: sigeia --> tellus,steterat,disguised,hic,leaden,wales,sovereignty,sailors,aedile,instant\n",
      "**********************************************************************************************\n",
      "Full   model target to context: stinking --> pour,pitch,down,beg,caps,weapons,their,seems,bound,tents\n",
      "Online model target to context: stinking --> pour,weapons,threw,their,caps,hurl,your,shock,graces,throw\n"
     ]
    }
   ],
   "source": [
    "# Pick the target words that has strong linked context words\n",
    "base_vocab_size = 3800\n",
    "num_top_target_words = 3\n",
    "num_top_context_words = 10\n",
    "\n",
    "target_words = np.argsort(np.max(full_sim[base_vocab_size:], axis=-1))[::-1][:num_top_target_words] + base_vocab_size\n",
    "\n",
    "# Find the top context words for each target word\n",
    "context_words_full = np.argsort(full_sim[target_words], axis=-1)[:,::-1][:,:num_top_context_words]\n",
    "context_words_online = np.argsort(online_sim[target_words], axis=-1)[:,::-1][:,:num_top_context_words]\n",
    "\n",
    "for idx, target_word in enumerate(target_words):\n",
    "    print('**********************************************************************************************')\n",
    "    print('Full   model target to context: {} --> {}'.format(vocab_list[target_word], ','.join(vocab_list[context_words_full[idx]])))\n",
    "    print('Online model target to context: {} --> {}'.format(vocab_list[target_word], ','.join(vocab_list[context_words_online[idx]])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47c61f-8f21-4fc9-9e96-8fa07994a8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
